{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Studies\n",
    "\n",
    "This notebook details the design and execution of ablation studies performed on a multi-agent system designed to solve Advent of Code puzzles. The system comprises several specialized AI agents, each responsible for a different stage of the problem-solving process: preprocessing, retrieval, planning, coding, and debugging.\n",
    "\n",
    "Ablation studies are a technique used to understand the contribution of individual components to the overall performance of a system. In this context, we will systematically disable specific agents within the system to observe how their absence impacts the system's ability to solve Advent of Code puzzles.\n",
    "\n",
    "The primary goal of these studies is to gain insights into the importance and effectiveness of each agent in the pipeline. By isolating the coding agent and disabling others in various combinations, we aim to identify which agents are most critical for successful problem-solving and how the interaction between agents influences the outcome.\n",
    "\n",
    "Through these experiments, we hope to better understand the system's architecture, identify potential areas for improvement, and inform future development efforts.\n",
    "\n",
    "**Agents in the System:**\n",
    "\n",
    "*   **Preprocessing Agent:** Handles initial processing and understanding of the puzzle description.\n",
    "*   **Retrieval Agent:** Responsible for retrieving relevant information, potentially from a knowledge base or past solutions.\n",
    "*   **Planning Agent:** Develops strategies and plans for solving the puzzle.\n",
    "*   **Coding Agent:** Generates the actual code solution based on the plan.\n",
    "*   **Debugging Agent:** Identifies and fixes errors in the generated code.\n",
    "\n",
    "In these ablation studies, the **Coding Agent will always remain enabled**, as it is essential for producing a code solution. The other agents will be selectively disabled to assess their impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- Setup the model to use\n",
    "- Load all the puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twanh/workspace/thesis/thesis-advent-of-agents/src/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import json\n",
    "from loguru import logger\n",
    "\n",
    "# Append the models path in order to import the models\n",
    "PROJECT_ROOT = os.path.join(os.getcwd(), 'src/')\n",
    "print(PROJECT_ROOT)\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Load env variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Set log level INFO\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load puzzles and input/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correct paths\n",
    "test_data_folder = os.path.join(PROJECT_ROOT, '..', 'experiments', 'test_data')\n",
    "puzzles_folder = os.path.join(test_data_folder, 'puzzles/')\n",
    "input_output_file = os.path.join(test_data_folder, 'answers2024.json')\n",
    "puzzle_files = [os.path.join(puzzles_folder, f) for f in os.listdir(puzzles_folder) if os.path.isfile(os.path.join(puzzles_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# Create a datastructure were we can get by day\n",
    "json_data = {}\n",
    "with open(input_output_file, 'r') as f:\n",
    "    json_data = {item['day']: item for item in json.load(f)}\n",
    "\n",
    "puzzle_data = []\n",
    "for file_path in puzzle_files:\n",
    "    # Get the day of the puzzle file\n",
    "    file_name = os.path.basename(file_path)\n",
    "    day_str = file_name.split('_')[-1].split('.')[0]\n",
    "    day = int(day_str)\n",
    "\n",
    "    if day in json_data:\n",
    "        with open(file_path, 'r') as f:\n",
    "            puzzle_description = f.read()\n",
    "\n",
    "        puzzle_info = {\n",
    "            \"year\": json_data[day]['year'],\n",
    "            \"day\": day,\n",
    "            \"description\": puzzle_description,\n",
    "            \"input\": json_data[day]['input'],\n",
    "            \"expected_output\": json_data[day]['part1']\n",
    "        }\n",
    "\n",
    "        puzzle_data.append(puzzle_info)\n",
    "\n",
    "# Sort by day\n",
    "puzzle_data.sort(key=lambda x: x['day'])\n",
    "print(len(puzzle_data)) # should be 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Ablation Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_configs = [\n",
    "    {\n",
    "        \"name\": \"baseline\",\n",
    "        \"preprocess\": True,\n",
    "        \"retrieval\": True,\n",
    "        \"planning\": True,\n",
    "        \"coding\": True,\n",
    "        \"debugging\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disable_preprocessing\",\n",
    "        \"preprocess\": False,\n",
    "        \"retrieval\": True,\n",
    "        \"planning\": True,\n",
    "        \"coding\": True,\n",
    "        \"debugging\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disable_retrieval\",\n",
    "        \"preprocess\": True,\n",
    "        \"retrieval\": False,\n",
    "        \"planning\": True,\n",
    "        \"coding\": True,\n",
    "        \"debugging\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disable_planning\",\n",
    "        \"preprocess\": True,\n",
    "        \"retrieval\": True,\n",
    "        \"planning\": False,\n",
    "        \"coding\": True,\n",
    "        \"debugging\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"disable_debugging\",\n",
    "        \"preprocess\": True,\n",
    "        \"retrieval\": True,\n",
    "        \"planning\": True,\n",
    "        \"coding\": True,\n",
    "        \"debugging\": False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.base_agent import BaseAgent\n",
    "from agents.coding_agent import CodingAgent\n",
    "from agents.debugging_agent import DebuggingAgent\n",
    "from agents.planning_agent import PlanningAgent\n",
    "from agents.pre_processing_agent import PreProcessingAgent\n",
    "from agents.retreival_agent import RetrievalAgent\n",
    "from core.orchestrator import Orchestrator\n",
    "from utils.util_types import AgentSettings\n",
    "from core.state import MainState\n",
    "from utils.util_types import Puzzle\n",
    "from models.base_model import BaseLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_system(config: dict[str, bool], model: BaseLanguageModel, expected_output: str, puzzle_input: str):\n",
    "\n",
    "    agents = (\n",
    "        (\n",
    "            PreProcessingAgent(\n",
    "                'preprocess', model=model,\n",
    "            ),\n",
    "            AgentSettings(enabled=config['preprocess'], can_debug=False),\n",
    "        ),\n",
    "        (\n",
    "            RetrievalAgent(\n",
    "                'retreival',\n",
    "                model=model,\n",
    "                connection_string=os.getenv('DB_CONNECTION_STRING') or '',\n",
    "                openai_key=os.getenv('OPENAI_API_KEY') or '',\n",
    "                weights=None, # Use default weights\n",
    "            ),\n",
    "            AgentSettings(enabled=config['retrieval'], can_debug=False),\n",
    "        ),\n",
    "        (\n",
    "            PlanningAgent(\n",
    "                'planning',\n",
    "                model=model,\n",
    "                n_plans=3, # Keep n_plans fixed for consistent comparison\n",
    "            ),\n",
    "            AgentSettings(enabled=config['planning'], can_debug=False),\n",
    "        ),\n",
    "        (\n",
    "            CodingAgent('coding', model=model),\n",
    "            AgentSettings(enabled=config['coding'], can_debug=False),\n",
    "        ),\n",
    "        (\n",
    "            DebuggingAgent(\n",
    "                'debugging',\n",
    "                model=model,\n",
    "                expected_output=expected_output,\n",
    "                puzzle_input=puzzle_input,\n",
    "            ),\n",
    "            AgentSettings(enabled=config['debugging'], can_debug=True),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    orchestrator = Orchestrator(agents, {})\n",
    "    return orchestrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils.util_types import TestCase\n",
    "\n",
    "def run_and_test_system(\n",
    "    day: int,\n",
    "    puzzle_desc: str,\n",
    "    puzzle_input: str,\n",
    "    expected_output: str,\n",
    "    config: dict[str, bool],\n",
    "    model: BaseLanguageModel\n",
    ") -> dict[str, str|int|None]:\n",
    "\n",
    "    orchestrator = setup_system(\n",
    "        config,\n",
    "        model,\n",
    "        expected_output=expected_output,\n",
    "        puzzle_input=puzzle_input\n",
    "    )\n",
    "\n",
    "\n",
    "    puzzle = Puzzle(\n",
    "        description=puzzle_desc,\n",
    "        solution=None,\n",
    "        year=2024,\n",
    "        day=day,\n",
    "    )\n",
    "\n",
    "    state = MainState(puzzle=puzzle)\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        ret_state = orchestrator.solve_puzzle(state)\n",
    "        end_time = time.time()\n",
    "\n",
    "        if not config['debugging']:\n",
    "            dba = DebuggingAgent(\n",
    "                'debugging',\n",
    "                model=model,\n",
    "                expected_output=expected_output,\n",
    "                puzzle_input=puzzle_input,\n",
    "            )\n",
    "            run_result = dba._run_test(\n",
    "                ret_state.generated_code or '',\n",
    "                TestCase(\n",
    "                    input_=puzzle_input,\n",
    "                    expected_output=expected_output,\n",
    "                ),\n",
    "            )\n",
    "            if run_result.success:\n",
    "                ret_state.is_solved = True\n",
    "                ret_state.final_code = ret_state.generated_code\n",
    "\n",
    "        return {\n",
    "            'success': ret_state.is_solved,\n",
    "            'day': day,\n",
    "            'name': config['name'],\n",
    "            'code': ret_state.final_code,\n",
    "            'debug_attempts': ret_state.debug_attempts,\n",
    "            'debug_suggestions': ret_state.debug_suggestions,\n",
    "            'n_retreived_puzzles': len(ret_state.retreived_puzzles),\n",
    "            'keywords': ','.join(ret_state.keywords),\n",
    "            'concepts': ','.join(ret_state.underlying_concepts),\n",
    "            'time': end_time - start_time\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Runtime error during puzzle solving for Day {day}: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'day': day,\n",
    "            'name': config['name'],\n",
    "            'code': None,\n",
    "            'debug_attempts': None,\n",
    "            'debug_suggestions': None,\n",
    "            'n_retreived_puzzles': None,\n",
    "            'keywords': None,\n",
    "            'concepts': None,\n",
    "            'time': None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "SAVE_DIR = os.path.join(PROJECT_ROOT, '../', 'experiments/', 'results/', 'ablation_studies/')\n",
    "\n",
    "def run_ablation(config, model, puzzle_data):\n",
    "\n",
    "    all_results = []\n",
    "    for puzzle in puzzle_data:\n",
    "        \n",
    "        puzzle_day = puzzle['day']\n",
    "        puzzle_description = puzzle['description']\n",
    "        input_ = puzzle['input']\n",
    "        expected_ouptut = puzzle['expected_output']\n",
    "        print(f\"Running day {puzzle_day}\")\n",
    "\n",
    "        results = run_and_test_system(\n",
    "            puzzle_day,\n",
    "            puzzle_description,\n",
    "            input_,\n",
    "            expected_output,\n",
    "            config,\n",
    "            model\n",
    "        )\n",
    "\n",
    "        all_results.append(results)\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'abl-{config[\"name\"]}-{timestamp}.csv'\n",
    "    filepath =os.path.join(SAVE_DIR, filename)\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    print(f\"Saving results for {config['name']} to {filepath}\")\n",
    "    results_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gemini_model import GeminiLanguageModel\n",
    "# Create language model to use\n",
    "model = GeminiLanguageModel(\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    model_name='gemini-2.0-flash'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1053638273.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f'----- RUNNING CONFIG {config[]}')\u001b[39m\n                                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for config in ablation_configs:\n",
    "\n",
    "    print(f'----- RUNNING CONFIG {config[\"name\"]} -----')\n",
    "    print(config)\n",
    "    result = run_ablation(config, model, puzzle_data)\n",
    "    results_list.append(result)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f'abl-full-{timestamp}.csv'\n",
    "filepath = os.path.join(SAVE_DIR, filename)\n",
    "results = pd.concat(results_list)\n",
    "results.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
